xlab="Calendar Month",
ylab="Average Delay (min)",
col="red",
type="b")
plot(by(LGA$dep_delay, LGA$month, function(x) mean(x, na.rm=T)),
xlab="Calendar Month",
ylab="Average Delay (min)",
col="blue",
type="b")
plot(by(EWR$dep_delay, EWR$month, function(x) mean(x, na.rm=T)),
xlab="Calendar Month",
ylab="Average Delay (min)",
col="green",
type="b")
plot(by(LGA$dep_delay, LGA$month, function(x) mean(x, na.rm=T)),
xlab="Calendar Month",
ylab="Average Delay (min)",
col="blue",
type="b")
fits <- fitted(mod2)
# Kevin McCraney
# Lab 4
# 02/21/2018
#
#
#
setwd("/Users/kmccraney/Desktop/ML-Lab")
data <- read.csv("census data.csv")
#
#
# 1. Make a new column representing >50k as a categorical variable.
data$income.g50 <- rep(0, nrow(data))
data$income.g50[data$income==" >50K"] <- 1
#
#
# 2.
mod <- glm(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"], family="binomial")
#
summary(mod)
#
# a. The log odds ratio for having a masters degree is 2.91 (statistically significant),
# while a 1st-4th grade education is -0.18 (not so). That is, compared to a 10th grade education, having
# a masters is...
exp(2.91)
# 18x greater. With my understanding of the way that work works in the modern era, it makes sense
# that there would be such a dramatic difference between the earning potential of a high-school dropout
# and someone who gets a master's.
#
exp(-0.47) < exp(-0.18)
#
# Curiously this is not the case for 1st-4th grade; it is actually more detrimental to have a 9th grade
# education. Where I previously attributed the change to the way the world works, I'd attribute this difference
# to the way our modern educational system works. If you get out early, or complete it on time, it won't
# negatively affect your earning potential as much, perhaps?
#
# If we are taking into account multiple comparisons (the idea that the more inferences we make, the more
# likely we are to produce error), it seems like the effects would compound greatly. We would have to be more
# strict for our significance threshold. We should probably pick the smallest of the small p-values then.
#
# b. The log odds ratio for being male increases by 1.29 (statistically significant), and age by 0.04
# (also statistically significant, to an equivalent degree). That means that being male increases "success"
# by almost fourfold. They are both definitely statistically significant, as the p-value is incredibly low.
#
# They are also practically significant. Men (especially men of a certain race) are given many more
# opportunities in education and in life, so there are compounding effects related to higher levels of
# education and wealth and so on.
#
# This is probably not fair, but part of that depends on your worldview. Men often take more risks in their
# career and with risk comes more opportunity for financial rewards, but at the same time women do a lot of
# unpaid and emotional labor, so they are working the same amount (or greater) for lesser rewards.
#
# Maybe for age it's fair. If you get older, you have more experience, and might get paid better?
#
#
# 3. Exploring Relationships II
x <- data$age
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
#
# The predicted probabilities are so variable for the reason we outlined above: that as we introduce
# more variables we introduce more potential for error, and have to address this by holding
# significance to a stronger standard. To practically interpret what I'm saying, in situations where
# the probability is already very high of someone making greater than 50k, it can't get much higher,
# so we can't effectively intuit the probability because some of the predictions are for marginal data.
#
#
# 4. Exploring probability cutoffs
#
#
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
#
# The lowest percent error is if we tabulate the data at 50%.
# The percent error corresponds to 20.6% error.
#
#
# 5. Examine the model
# a. plot the curve
#
library(AUC)
y <- factor(data$income.g50)
rr <- roc(fits, y)
plot(rr)
auc(rr)
#
# b. and gauge how well it fits
#
# After calculating the AUC, it seems like the model accurately represents 80.2% of the data.
# I'd say that's pretty good--it's better than chance, and doesn't seem like overfit.
#
#
# 6. Formulate another model.
#
mod2 <- glm(income.g50~.,
data=data[,!colnames(data)%in%c("income")], family="binomial")
#
summary(mod2)
#
# Interestingly, the odds have changed (in some cases dramatically,
# and in some cases slightly), but the same categories that were previously
# significant have retained their significance, and actually gone up in terms of their significance.
#
#
plot(x, mod2, col="blue")
fits <- fitted(mod2)
points(x, fits, pch=19, cex=0.3)
#
#
#
#
#
# Extra Credit:
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
tab25
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
length(mod)
length(mod2)
length(x)
x <- data$age
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
plot(x, data$income.g50, col="blue")
fits <- fitted(mod2)
points(x, fits, pch=19, cex=0.3)
x <- data$age
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
plot(x, data$income.g50, col="blue")
fits <- fitted(mod2)
points(x, fits, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
x <- data$age
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
plot(x, data$income.g50, col="blue")
fits <- fitted(mod2)
points(x, fits, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
plot(x, data$income.g50~., col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
plot(x, data$income.g50~, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
x <- data$age
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
alttab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
alttab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
alttab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
alttab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
alttab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
alttab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
mod2 <- glm(income.g50~.,
data=data[,!colnames(data)%in%c("income")], family="binomial")
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
alttab25 <- table(data$income.g50, fits>=0.25)
(alttab25[1,2]+tab25[2,1])/sum(tab25)
#
alttab50 <- table(data$income.g50, fits>=0.5)
(alttab50[1,2]+tab50[2,1])/sum(tab50)
#
alttab75 <- table(data$income.g50, fits>=0.75)
(alttab75[1,2]+tab75[2,1])/sum(tab75)
y <- factor(data$income.g50)
rr2 <- roc(fits2, y)
plot(rr2)
auc(rr2)
plot(rr)
auc(rr)
y <- factor(data$income.g50)
rr2 <- roc(fits2, y)
plot(rr2)
auc(rr2)
mod2 <- glm(income.g50~.,
data=data[,!colnames(data)%in%c("income")], family="binomial")
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
alttab25 <- table(data$income.g50, fits>=0.25)
(alttab25[1,2]+alttab25[2,1])/sum(alttab25)
#
alttab50 <- table(data$income.g50, fits>=0.5)
(alttab50[1,2]+alttab50[2,1])/sum(alttab50)
#
alttab75 <- table(data$income.g50, fits>=0.75)
(alttab75[1,2]+alttab75[2,1])/sum(alttab75)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
alttab25
tab25
mod2 <- glm(income.g50~.,
data=data[,!colnames(data)%in%c("income")], family="binomial")
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
alttab25
tab25
data$income.g50
y <- factor(data$income.g50)
rr2 <- roc(fits2, y)
plot(rr2)
auc(rr2)
mod
mod2
plot(x, data$income.g50, col="blue")
fits2 <- fitted(mod2)
points(x, fits2, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
tab25
alttab25
fits2
data$income.g50
alttab25 <- table(data$income.g50, fits2>=0.25)
(alttab25[1,2]+alttab25[2,1])/sum(alttab25)
#
alttab50 <- table(data$income.g50, fits2>=0.5)
(alttab50[1,2]+alttab50[2,1])/sum(alttab50)
#
alttab75 <- table(data$income.g50, fits2>=0.75)
(alttab75[1,2]+alttab75[2,1])/sum(alttab75)
library(caret)
set.seed(23434)
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval2 <- train(income.g50~.,
data=data[,!colnames(data)%in%"income"],
method="lm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
warnings()
kval1
kval2
kval1 > kval2
plot(x, data$income.g50, col="blue")
fits2 <- fitted(kval1)
points(x, fits2, pch=19, cex=0.3)
plot(x, data$income.g50, col="blue")
fits2 <- fitted(kval2)
points(x, fits2, pch=19, cex=0.3)
rr3 <- roc(kval1, y)
plot(rr3)
auc(rr3)
rr3 <- roc(kval1, y)
rr3 <- roc(kval1, y)
kval1$pred
kval1
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
trControl= trainControl(
method="cv", number=3,
verboseIter = TRUE
))
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="glm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kval2 <- train(income.g50~.,
data=data[,!colnames(data)%in%"income"],
method="glm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval2
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
#
# And here's 2:
#
kval2 <- train(income.g50~.,
data=data[,!colnames(data)%in%"income"],
method="lm",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kmod2
kval2
x <- data$age
plot(x, data$income.g50, col="blue")
fits <- fitted(mod)
points(x, fits, pch=19, cex=0.3)
tab25 <- table(data$income.g50, fits>=0.25)
(tab25[1,2]+tab25[2,1])/sum(tab25)
#
tab50 <- table(data$income.g50, fits>=0.5)
(tab50[1,2]+tab50[2,1])/sum(tab50)
#
tab75 <- table(data$income.g50, fits>=0.75)
(tab75[1,2]+tab75[2,1])/sum(tab75)
y <- factor(data$income.g50)
rr <- roc(fits, y)
plot(rr)
auc(rr)
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
metric="ROC",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
tuneLength=30,
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
tuneLength=30,
metric="ROC",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
tuneLength=30,
metric="ROC",
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE,
classProbs=TRUE
))
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
tuneLength=30,
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kval1 <- train(income.g50 ~ education + age + sex + race,
data=data[,!colnames(data)%in%"income"],
method="lm",
tuneLength=9,
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kval2 <- train(income.g50~.,
data=data[,!colnames(data)%in%"income"],
method="lm",
tuneLength=9,
trControl= trainControl(
method="cv", number=10,
verboseIter = TRUE
))
kval1
kval2
